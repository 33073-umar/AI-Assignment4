{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20628 images belonging to 36 classes.\n",
      "Found 1008 images belonging to 36 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ashad InnO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ashad InnO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m644/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1744 - loss: 2.9314\n",
      "Epoch 1: val_accuracy improved from -inf to 0.79464, saving model to cnn_improved.keras\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 137ms/step - accuracy: 0.1748 - loss: 2.9296 - val_accuracy: 0.7946 - val_loss: 0.7228 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5556 - loss: 1.4146\n",
      "Epoch 2: val_accuracy improved from 0.79464 to 0.88194, saving model to cnn_improved.keras\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - accuracy: 0.5556 - loss: 1.4144 - val_accuracy: 0.8819 - val_loss: 0.4206 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m644/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6680 - loss: 1.0380\n",
      "Epoch 3: val_accuracy did not improve from 0.88194\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 41ms/step - accuracy: 0.6680 - loss: 1.0378 - val_accuracy: 0.8700 - val_loss: 0.4012 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m643/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7191 - loss: 0.8873\n",
      "Epoch 4: val_accuracy improved from 0.88194 to 0.92460, saving model to cnn_improved.keras\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - accuracy: 0.7192 - loss: 0.8872 - val_accuracy: 0.9246 - val_loss: 0.2315 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m644/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7510 - loss: 0.7828\n",
      "Epoch 5: val_accuracy improved from 0.92460 to 0.92956, saving model to cnn_improved.keras\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.7510 - loss: 0.7827 - val_accuracy: 0.9296 - val_loss: 0.1963 - learning_rate: 0.0010\n",
      "Epoch 6/15\n",
      "\u001b[1m644/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7795 - loss: 0.6924\n",
      "Epoch 6: val_accuracy improved from 0.92956 to 0.93651, saving model to cnn_improved.keras\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.7795 - loss: 0.6924 - val_accuracy: 0.9365 - val_loss: 0.1933 - learning_rate: 0.0010\n",
      "Epoch 7/15\n",
      "\u001b[1m644/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7914 - loss: 0.6576\n",
      "Epoch 7: val_accuracy improved from 0.93651 to 0.95040, saving model to cnn_improved.keras\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - accuracy: 0.7914 - loss: 0.6575 - val_accuracy: 0.9504 - val_loss: 0.1576 - learning_rate: 0.0010\n",
      "Epoch 8/15\n",
      "\u001b[1m644/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8045 - loss: 0.6128\n",
      "Epoch 8: val_accuracy did not improve from 0.95040\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 40ms/step - accuracy: 0.8045 - loss: 0.6128 - val_accuracy: 0.9246 - val_loss: 0.1906 - learning_rate: 0.0010\n",
      "Epoch 9/15\n",
      "\u001b[1m642/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8133 - loss: 0.5794\n",
      "Epoch 9: val_accuracy improved from 0.95040 to 0.95437, saving model to cnn_improved.keras\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.8133 - loss: 0.5794 - val_accuracy: 0.9544 - val_loss: 0.1456 - learning_rate: 0.0010\n",
      "Epoch 10/15\n",
      "\u001b[1m643/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8235 - loss: 0.5563\n",
      "Epoch 10: val_accuracy did not improve from 0.95437\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - accuracy: 0.8235 - loss: 0.5563 - val_accuracy: 0.9544 - val_loss: 0.1314 - learning_rate: 0.0010\n",
      "Epoch 11/15\n",
      "\u001b[1m643/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8287 - loss: 0.5273\n",
      "Epoch 11: val_accuracy did not improve from 0.95437\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.8286 - loss: 0.5273 - val_accuracy: 0.9514 - val_loss: 0.1370 - learning_rate: 0.0010\n",
      "Epoch 12/15\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8328 - loss: 0.5203\n",
      "Epoch 12: val_accuracy improved from 0.95437 to 0.96230, saving model to cnn_improved.keras\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - accuracy: 0.8328 - loss: 0.5203 - val_accuracy: 0.9623 - val_loss: 0.1086 - learning_rate: 0.0010\n",
      "Epoch 13/15\n",
      "\u001b[1m644/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8395 - loss: 0.4977\n",
      "Epoch 13: val_accuracy did not improve from 0.96230\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - accuracy: 0.8395 - loss: 0.4977 - val_accuracy: 0.9276 - val_loss: 0.1666 - learning_rate: 0.0010\n",
      "Epoch 14/15\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8378 - loss: 0.5014\n",
      "Epoch 14: val_accuracy did not improve from 0.96230\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.8378 - loss: 0.5014 - val_accuracy: 0.9623 - val_loss: 0.1191 - learning_rate: 0.0010\n",
      "Epoch 15/15\n",
      "\u001b[1m643/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8415 - loss: 0.4960\n",
      "Epoch 15: val_accuracy did not improve from 0.96230\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 39ms/step - accuracy: 0.8415 - loss: 0.4960 - val_accuracy: 0.9554 - val_loss: 0.1063 - learning_rate: 0.0010\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9584 - loss: 0.1032\n",
      "Test accuracy: 0.9553571343421936\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "Accuracy: 0.9623015873015873\n",
      "Precision: 0.9731196405765371\n",
      "Recall: 0.9623015873015873\n",
      "F1 Score: 0.9602886202475933\n",
      "Confusion Matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0 26  0 ...  0  0  0]\n",
      " [ 0  0 28 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 28  0  0]\n",
      " [ 0  0  0 ...  0 28  0]\n",
      " [ 0  0  0 ...  0  0 28]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define paths\n",
    "train_dir = 'training_data'\n",
    "test_dir = 'testing_Data'\n",
    "image_height = 32  \n",
    "image_width = 32  \n",
    "channels = 3\n",
    "\n",
    "# Load datasets with data augmentation for the training set\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "test_dataset = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, channels)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(36, activation='softmax')\n",
    "])\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'cnn_improved.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_callback = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=0.0001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=15,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback, reduce_lr_callback]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "# Load and evaluate the model with additional metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.models.load_model('cnn_improved.keras')\n",
    "\n",
    "# Get the true labels and predictions\n",
    "y_true = np.concatenate([test_dataset[i][1] for i in range(len(test_dataset))])\n",
    "y_pred = np.argmax(model.predict(test_dataset), axis=-1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
