{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=  24.6s\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=  25.5s\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=  26.0s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=  11.3s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=   6.5s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=   5.6s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=  37.1s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=  36.7s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=  47.9s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=  10.4s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=   8.2s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=   7.0s\n",
      "[CV] END .................................C=10, solver=lbfgs; total time=  43.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ashad InnO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................C=10, solver=lbfgs; total time= 1.1min\n",
      "[CV] END .................................C=10, solver=lbfgs; total time=  39.7s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=  11.9s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=   8.4s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=   7.6s\n",
      "Best Parameters: {'C': 1, 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ashad InnO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4628/4628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.7144 - loss: 1.5009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ashad InnO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3703/3703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.6959 - loss: 1.7420\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m3703/3703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 1.7375\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m3703/3703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.6951 - loss: 1.7598\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m3703/3703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.6855 - loss: 1.7924\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m3703/3703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.6961 - loss: 1.7449\n",
      "\u001b[1m926/926\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m1157/1157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Confusion Matrix (Stacking):\n",
      "[[10280  3576]\n",
      " [ 2718 20450]]\n",
      "\n",
      "Metrics (Stacking):\n",
      "Accuracy: 0.8300021607605877\n",
      "Precision: 0.8511612419878465\n",
      "Recall: 0.8826830110497238\n",
      "F1-score: 0.8666355892698224\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('drugs.csv', nrows=200000)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Ensure ratings are numeric and filter out invalid entries\n",
    "df = df[pd.to_numeric(df['Rating'], errors='coerce').notnull()]\n",
    "df.loc[:, 'Rating'] = df['Rating'].astype(float)\n",
    "\n",
    "# Convert text data into TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['Content']).toarray()\n",
    "\n",
    "# Target variable\n",
    "y = df['Rating'].values\n",
    "\n",
    "# Transform ratings to categorical labels for classification\n",
    "y = np.where(y >= 6, 1, 0)  # Example: ratings >= 6 are considered positive (1), others are negative (0)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load pre-trained Keras model\n",
    "mlp_model = load_model('mlp_model.h5')\n",
    "\n",
    "# Wrap Keras model for use in scikit-learn\n",
    "mlp_wrapper = KerasClassifier(model=mlp_model)\n",
    "\n",
    "# Load pre-trained Naive Bayes model\n",
    "nb_model = joblib.load('naive_bayes_model.joblib')\n",
    "\n",
    "# Define meta-model with hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'solver': ['lbfgs', 'liblinear']  # Optimization algorithm\n",
    "}\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=meta_model, param_grid=param_grid, cv=3, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Display best parameters\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Update meta-model with best parameters\n",
    "meta_model.set_params(**best_params)\n",
    "\n",
    "# Create stacking ensemble\n",
    "estimators = [('mlp', mlp_wrapper), ('nb', nb_model)]\n",
    "stacking_model = StackingClassifier(estimators=estimators, final_estimator=meta_model)\n",
    "\n",
    "# Train stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the stacking model\n",
    "joblib.dump(stacking_model, 'stacking_model.joblib')\n",
    "\n",
    "# Predict on the test set with the stacking model\n",
    "y_pred_stacking = stacking_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for the stacking model\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_stacking)\n",
    "accuracy = accuracy_score(y_test, y_pred_stacking)\n",
    "precision = precision_score(y_test, y_pred_stacking)\n",
    "recall = recall_score(y_test, y_pred_stacking)\n",
    "f1 = f1_score(y_test, y_pred_stacking)\n",
    "\n",
    "# Display metrics\n",
    "print(\"Confusion Matrix (Stacking):\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nMetrics (Stacking):\"   )\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
